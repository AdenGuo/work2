{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this answer, three models have been build by using given data to predict hourly entries in NYC subways .\n",
    "\n",
    "The first model is a simple linear regression model.\n",
    "\n",
    "The second one is a two-level regression model.\n",
    "\n",
    "The third one is a nonparametric model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This article is divided into 5 parts.\n",
    "\n",
    "1, Some observations and thoughts from data.\n",
    "\n",
    "2, General principles of models.\n",
    "\n",
    "3, Three models.\n",
    "\n",
    "4, Summary.\n",
    "\n",
    "5, Possible further improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Some observtions and thoughts from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is about ridership of NYC subways. Here is a typical record in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                  0\n",
      "UNIT                     R001\n",
      "DATEn              2011-05-01\n",
      "TIMEn                01:00:00\n",
      "Hour                        1\n",
      "DESCn                 REGULAR\n",
      "ENTRIESn_hourly             0\n",
      "EXITSn_hourly               0\n",
      "maxpressurei            30.31\n",
      "maxdewpti                  42\n",
      "mindewpti                  35\n",
      "minpressurei            30.23\n",
      "meandewpti                 39\n",
      "meanpressurei           30.27\n",
      "fog                         0\n",
      "rain                        0\n",
      "meanwindspdi                5\n",
      "mintempi                   50\n",
      "meantempi                  60\n",
      "maxtempi                   69\n",
      "precipi                     0\n",
      "thunder                     0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from linear_models import load_data\n",
    "dataframe = load_data()\n",
    "print dataframe.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the meaning of various data fields in this record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnamed: 0: Meaningless.\n",
    "\n",
    "UNIT: Remote unit that collects turnstile information. Can collect from multiple banks of turnstiles. \n",
    "Large subway stations can have more than one unit. \n",
    "\n",
    "DATEn: Date in “yyyy-mm-dd” (2011-05-21) format. \n",
    "\n",
    "TIMEn: Time in “hh:mm:ss” (08:05:02) format. \n",
    "\n",
    "hour: Hour of the timestamp from TIMEn. Truncated rather than rounded. \n",
    "\n",
    "DEScn: Represent the \"REGULAR\" scheduled audit event (occurs every 4 hours).\n",
    "\n",
    "ENTRIESn_hourly: Difference in ENTRIES from the previous REGULAR reading. \n",
    "\n",
    "EXITSn_hourly: Difference in EXITS from the previous REGULAR reading.\n",
    "\n",
    "maxpressurei: Maximum pressure in inHg.\n",
    "\n",
    "maxdewpti: Maximum dewpoint in F.\n",
    "\n",
    "mindewpti: Minimum dewpoint in F.\n",
    "\n",
    "minpressurei: Minimum pressure in inHg.\n",
    "\n",
    "meandewpti: Mean dewpoint in F.\n",
    "\n",
    "meanpressurei: Mean pressure in inHg.\n",
    "\n",
    "fog: Indication of appearance of fog.\n",
    "\n",
    "rain: Indication of appearance of rain.\n",
    "\n",
    "meanwindspdi: Mean windspeed in mph.\n",
    "\n",
    "mintempi: Minimum temperature in F.\n",
    "\n",
    "meantempi: Mean temperature in F.\n",
    "\n",
    "maxtempi: Maximum temperature in F.\n",
    "\n",
    "precipi: Precipitation in inches.\n",
    "\n",
    "thunder: Indication of appearance of thunder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model should be build based on the dataset. In this model the date item \"ENTRIESn_hourly\" is the value to be predicted. This is the output of the model. The other items which represent date, time and weather conditions are the values used to predict \"ENTRIESn_hourly\". These are inputs of the model. These inputs are also called features. The center task of model is using features to calculate output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this task is to predict numerical values. The simplest model is by unifying some features into a simple linear models. The simple linear model have following form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "y=\\beta_1*x_1+\\beta_2*x_2+...+\\beta_k*x_k+\\epsilon\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$y$ is the output. $x_1, x_2...x_k$ are the values of features. $\\beta_1, \\beta_2...\\beta_k$are so called weights or coefficients which will be determined by training process. $\\epsilon$ is the estimated error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions are made by utlizing this simple linear model. One important assumption is independence of features. That is the change of one feature will not effect other features. However, some observations may indicate that the features may be dependent on each other. Here is the form that show some correlation between feature \"rain\" and fearure \"hour\" in a particular turnstile. The values in the form is the average \"hourly_entries\" given the \"rain\" and \"hour\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              no_rain    rain\n",
      "17:00:00  5734.750000  5259.2\n",
      "13:00:00  6423.850000  6538.6\n",
      "09:00:00  4340.736842  4554.5\n",
      "01:00:00  1990.263158  1711.6\n",
      "21:00:00  4644.157895  4900.4\n"
     ]
    }
   ],
   "source": [
    "from observations import rain_correlated_time\n",
    "unit_number = 1\n",
    "time_number = 5\n",
    "print rain_correlated_time(unit_number, time_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for some \"hour\", the average \"hourly_entries\" is higher when \"rain\" is 1. And for other, the average \"hourly_entries\" is lower. This observation shows that the feature \"rain\" is dependent on the feature \"hour\". This observation is intuitive. When it is raining(corresponding to feature \"rain\") in mid-night(corresponding to feature \"hour\"), the ridership of subway may not be affected by rain. And if it was raining in rush hour, more people may take subway to work because the traffic on the road may become terrible in rainy days. These thoughts on causation may not be accurate. The center idea is features are not independent. A model with consideration of correlation should be build. Here is a typical formula of two-level regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "&y=\\beta_1(u_1,u_2...u_l)*x_1+\\beta_2(u_1,u_2...u_l)*x_2+...+\\beta_k(u_1,u_2...u_l)*x_k+\\epsilon \\\\\n",
    "&\\beta_1(u_1,u_2...u_l) = f_1(u_1,u_2...u_l) \\\\\n",
    "&\\beta_2(u_1,u_2...u_l) = f_2(u_1,u_2...u_l) \\\\\n",
    "&... \\\\\n",
    "&\\beta_k(u_1,u_2...u_l) = f_k(u_1,u_2...u_l)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y$ is the output. $x_1, x_2...x_k$ are the values of level-two features. $\\beta_1(u_1,u_2...u_l), \\beta_2(u_1,u_2...u_l)...\\beta_k(u_1,u_2...u_l)$are so called coefficients functions which will be determined by  model and training process. $\\epsilon$ is the estimated error. $u_1, u_2...u_l$ are values of level-one features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, when people talked about crowdedness of the subways. They may say, there are a lot people in this station 5:00 pm yestoday and a lot people will be in this station at the same time. Following figures show ridership in different days at and in one particular station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pylab.backend_inline",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-99e64dacfed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'pylab inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobservations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_daily_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mobservations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0munit_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_daily_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munit_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2302\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2303\u001b[0m         \"\"\"Find and return a cell magic by name.\n\u001b[1;32m-> 2304\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2305\u001b[0m         Returns None if the magic isn't found.\"\"\"\n\u001b[0;32m   2306\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagics_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cell'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2223\u001b[0m         self.magics_manager.register_function(func, \n\u001b[0;32m   2224\u001b[0m                                   magic_kind=magic_kind, magic_name=magic_name)\n\u001b[1;32m-> 2225\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2227\u001b[0m         \"\"\"Execute the given line magic.\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/IPython/core/magics/pylab.pyc\u001b[0m in \u001b[0;36mpylab\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/IPython/core/magics/pylab.pyc\u001b[0m in \u001b[0;36mpylab\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[1;32mpass\u001b[0m \u001b[1;33m`\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mno\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;32mimport\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mtwo\u001b[0m \u001b[1;33m`\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mimports\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mexcluded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mmatplotlib\u001b[0m \u001b[0mmagic\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m \u001b[0mabout\u001b[0m \u001b[0mactivating\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mwithout\u001b[0m \u001b[0maffecting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minteractive\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36menable_pylab\u001b[1;34m(self, gui, import_all, welcome_message)\u001b[0m\n\u001b[0;32m   3135\u001b[0m         \u001b[1;31m# Now we must activate the gui pylab wants to use, and fix %run to take\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3136\u001b[0m         \u001b[1;31m# plot updates into account\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3137\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_gui\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3138\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagics_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ExecutionMagics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_runner\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3139\u001b[0m             \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpl_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_execfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3096\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Implement enable_gui in a subclass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3098\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgui\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3099\u001b[0m         \"\"\"Enable interactive matplotlib and inline figure support.\n\u001b[0;32m   3100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mactivate_matplotlib\u001b[1;34m(backend)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;31m# This must be imported last in the matplotlib series, after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mswitch_backend\u001b[1;34m(newbackend)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewbackend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0m_backend_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_figure_manager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_show\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adenguo/anaconda/lib/python2.7/site-packages/matplotlib/backends/__init__.pyc\u001b[0m in \u001b[0;36mpylab_setup\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# imports. 0 means only perform absolute imports.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     backend_mod = __import__(backend_name,\n\u001b[1;32m---> 32\u001b[1;33m                              globals(),locals(),[backend_name],0)\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Things we pull in from all backends\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named pylab.backend_inline"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from observations import plot_daily_data\n",
    "import observations\n",
    "unit_number = 1\n",
    "plot_daily_data(unit_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the picture reveals, the ridership is periodical. The similar amount of hourly entries will appear repeatedly based on same time of different days. This provide the philosophy of non-parametric model. The general formula of non-parametric model is as following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "y=f(D_1, D_2,...D_n)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y$ is the output. $D_1, D_2, ...D_n$ are records from dataset. $f()$ is a general form of function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##General principles of model constructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the features are the same for three models. I select following features as input of models. \n",
    "\n",
    "'unit'(I translated this variable into a dummy variable indicating if a record belongs to a specific turnstile in linear model and two-level regression model)\n",
    "\n",
    "'hour'(I translate this variable to 'dec_time')\n",
    "\n",
    "'meantempi'\n",
    "\n",
    "'rain'\n",
    "\n",
    "'meanwindspdi'\n",
    "\n",
    "'precipi'\n",
    "\n",
    "'DATEn'(I translated this variable to 'weeksday' which represent Sunday, Monday and etc. in a numerical way and 'is_weekend' which using bool value represent if it is a weekend.)    \n",
    "\n",
    "However, these features play different roles in three models.\n",
    "\n",
    "I also translate the output 'ENTRIESn_hourly' into 'hourly_entries' in implementation of three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, the whole dataset is split into training and test dataset. Three model are all trained based on same training data and evaluated on test data. Two measurements for models are used which are sum squared error(SSE) and R-square(R2) value. The split of dataset were done for ten times. And each model is trained and evaluated for ten times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Three models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Simple linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features : the model was built as a conventional linear model. Intercept is included in this model. These features of the model are dummy variables for 'unit'(total 465 variables), 'dec_time', 'meantempi', 'rain', 'meanwindspdi', 'precipi' and 'is_weekend'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training: the model is trained using ordinary least squares(OLS) implemented in statsmodels package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting: Values of the record are directly used to evaluate the number of hourly entries in the linear regression function. And a little non-linearity is done on the predicted value. If the predicted value is small than zero. It is set to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the training and evaluating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from linear_models import *\n",
    "\n",
    "#Set time_intervals for a simple linear model\n",
    "time_intervals = [(0,23.999,weeks_day)]\n",
    "\n",
    "#features will be used in linear models\n",
    "features_list = ['rain','meantempi', 'dec_time','meanwindspdi','precipi', 'is_weekend']\n",
    "\n",
    "#Phase 1, preprocessing and save result. \n",
    "dataframe = load_data()\n",
    "new_dataframe = create_new_dateframe_0(dataframe)\n",
    "new_dataframe = add_datetime_str(new_dataframe)\n",
    "new_dataframe = add_dec_time(new_dataframe)\n",
    "new_dataframe = add_weeksday(new_dataframe)\n",
    "new_dataframe = add_is_weekend(new_dataframe)\n",
    "new_dataframe, dummy_unit_list = add_dummy_unit(new_dataframe)\n",
    "features_list.extend(dummy_unit_list)\n",
    "write_features_to_file(features_list, '../features_list')\n",
    "new_dataframe.to_csv('../new_weather_turnstile.csv')\n",
    "dataframe = pandas.read_csv('../new_weather_turnstile.csv')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "test_propotion = 0.1\n",
    "train_new_weather_turnstile, test_new_weather_turnstile = \\\n",
    "train_test_split(dataframe, test_size = test_propotion)\n",
    "train_new_weather_turnstile.to_csv('../train_new_weather_turnstile.csv')\n",
    "test_new_weather_turnstile.to_csv('../test_new_weather_turnstile.csv')\n",
    "\n",
    "#Phase 2, building model and save result\n",
    "features_list = read_features_from_file('../features_list')\n",
    "dataframe = pandas.read_csv('../train_new_weather_turnstile.csv')\n",
    "coeff_matrix = create_coeff_matrix(features_list, time_intervals, dataframe)\n",
    "coeff_matrix.to_csv('../coeff_matrix.csv')\n",
    "\n",
    "#Phase 3, Test and evaluating\n",
    "features_list = read_features_from_file('../features_list')\n",
    "coeff_matrix = pandas.read_csv('../coeff_matrix.csv')\n",
    "test_dataframe = pandas.read_csv('../test_new_weather_turnstile.csv')\n",
    "predictions = make_predictions_dataframe(test_dataframe, time_intervals,\\\n",
    "                                         features_list, coeff_matrix)\n",
    "sum_square_complex = compute_sum_square(test_dataframe['hourly_entries'], predictions)\n",
    "r_square_complex = compute_r_squared(test_dataframe['hourly_entries'], predictions)\n",
    "\n",
    "print \"SSE is \"+ str(sum_square_complex)\n",
    "print \"R2 is \"+ str(r_square_complex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this calculation, the SSE is 38615772513.4 and R2 is 0.467863803062. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexity: computational complexity is evaluated on predicting process. The time of predicting a record is O(1) which is constant time for evaluating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Two level regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features : the features are grouped into two level. Coefficients of level two features are functions of level one features (see the formula above). Level two features are 'unit'(total 465 variables), 'dec_time', 'meantempi', 'rain', 'meanwindspdi' and 'precipi'. Level one features are 'dec_time' and 'weeksday'. It is worth noting that 'dec_time' is both level one and level two feature. I think that this variable is correlated with itselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training: the level-one features are divided into intervals such as 00:00 to 05:00 in weeksday and 13:00 to 16:00 in weekend. And the training data are filtered by these intervals. Each interval will be corresponding to a subset of data. Then a linear regression model with level two features was training based on each of these subsets. every model is trained using ordinary least squares(OLS) implemented in statsmodels package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting: The predicting is a two-step process. First step is choosing which group of coefficients to use based on level one features. Second step is computing number of hourly entries based on chosen coefficients and level two features. Also, a little non-linearity is done on the predicted value. If the predicted value is small than zero. It is set to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the training and evaluating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from linear_models import *\n",
    "\n",
    "#Set time_intervals for a simple linear model\n",
    "time_intervals = [(0,4,works_day), (4,8,works_day), (8,12,works_day), \\\n",
    "                  (12,16,works_day), (16,20,works_day), (20,23.999,works_day),\\\n",
    "                  (0,4,weekend), (4,8,weekend), (8,12,weekend), \\\n",
    "                  (12,16,weekend), (16,20,weekend), (20,23.999,weekend)]\n",
    "\n",
    "#features will be used in linear models\n",
    "features_list = ['rain','meantempi', 'dec_time','meanwindspdi','precipi']\n",
    "\n",
    "#Phase 1, preprocessing and save result. \n",
    "dataframe = load_data()\n",
    "new_dataframe = create_new_dateframe_0(dataframe)\n",
    "new_dataframe = add_datetime_str(new_dataframe)\n",
    "new_dataframe = add_dec_time(new_dataframe)\n",
    "new_dataframe = add_weeksday(new_dataframe)\n",
    "new_dataframe = add_is_weekend(new_dataframe)\n",
    "new_dataframe, dummy_unit_list = add_dummy_unit(new_dataframe)\n",
    "features_list.extend(dummy_unit_list)\n",
    "write_features_to_file(features_list, '../features_list')\n",
    "new_dataframe.to_csv('../new_weather_turnstile.csv')\n",
    "dataframe = pandas.read_csv('../new_weather_turnstile.csv')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "test_propotion = 0.1\n",
    "train_new_weather_turnstile, test_new_weather_turnstile = \\\n",
    "train_test_split(dataframe, test_size = test_propotion)\n",
    "train_new_weather_turnstile.to_csv('../train_new_weather_turnstile.csv')\n",
    "test_new_weather_turnstile.to_csv('../test_new_weather_turnstile.csv')\n",
    "\n",
    "#Phase 2, building model and save result\n",
    "features_list = read_features_from_file('../features_list')\n",
    "dataframe = pandas.read_csv('../train_new_weather_turnstile.csv')\n",
    "coeff_matrix = create_coeff_matrix(features_list, time_intervals, dataframe)\n",
    "coeff_matrix.to_csv('../coeff_matrix.csv')\n",
    "\n",
    "#Phase 3, Test and evaluating\n",
    "features_list = read_features_from_file('../features_list')\n",
    "coeff_matrix = pandas.read_csv('../coeff_matrix.csv')\n",
    "test_dataframe = pandas.read_csv('../test_new_weather_turnstile.csv')\n",
    "predictions = make_predictions_dataframe(test_dataframe, time_intervals,\\\n",
    "                                         features_list, coeff_matrix)\n",
    "sum_square_complex = compute_sum_square(test_dataframe['hourly_entries'], predictions)\n",
    "r_square_complex = compute_r_squared(test_dataframe['hourly_entries'], predictions)\n",
    "\n",
    "print \"SSE is \"+ str(sum_square_complex)\n",
    "print \"R2 is \"+ str(r_square_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this calculation, the SSE is 11897041343.3 and R2 is 0.837420573143. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexity: computational complexity is evaluated on predicting process. The time of predicting a record is O(1) which is constant. This constant time is a little longer than that of simple linear model. But I think the difference can be safely neglected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Non-parametric model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: Features for non-parametric model are 'unit', 'dec_time', 'meantempi', 'rain', 'meanwindspdi', 'precipi' and 'is_weekend'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and predicting: Features are divided into two groups. One is categorical features and the other is numerical features. A subset of data is created by selecting records whose categorical feature are identical to the record(unknown record) which is under predicting. The weighted euclidean distances between unknown record and every record in the subset are calculated based on numerical features. k records with smallest distance are selected. The number of hourly entries are average of hourly entries of these k record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the training and evaluating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nonparametric_model import *\n",
    "\n",
    "\n",
    "#Set features for nonparametric model\n",
    "numeric_features_list_with_weight = [('meantempi',1), ('dec_time',2), \\\n",
    "                                     ('meanwindspdi',1),('precipi',1)]\n",
    "categorical_features = ['unit', 'rain', 'is_weekend']\n",
    "delta = 2\n",
    "k = 10\n",
    "\n",
    "#Phase 1, preprocessing and save result. \n",
    "dataframe = load_data()\n",
    "new_dataframe = create_new_dateframe_0(dataframe)\n",
    "new_dataframe = add_datetime_str(new_dataframe)\n",
    "new_dataframe = add_dec_time(new_dataframe)\n",
    "new_dataframe = add_weeksday(new_dataframe)\n",
    "new_dataframe = add_is_weekend(new_dataframe)\n",
    "write_features_with_weight_to_file(numeric_features_list_with_weight, \\\n",
    "                                   '../numeric_features_list_weight')\n",
    "write_features_to_file(categorical_features, '../categorical_features')\n",
    "new_dataframe.to_csv('../new_weather_turnstile.csv')\n",
    "dataframe = pandas.read_csv('../new_weather_turnstile.csv')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "test_propotion = 0.1\n",
    "train_new_weather_turnstile, test_new_weather_turnstile = \\\n",
    "train_test_split(dataframe, test_size = test_propotion)\n",
    "train_new_weather_turnstile.to_csv('../train_new_weather_turnstile.csv')\n",
    "test_new_weather_turnstile.to_csv('../test_new_weather_turnstile.csv')\n",
    "\n",
    "#Phase 2, predicting and evaluating\n",
    "numeric_features_list_with_weight = read_features_with_weight_from_file \\\n",
    "                                    ('../numeric_features_list_weight')\n",
    "categorical_features = read_features_from_file('../categorical_features')\n",
    "dataframe = pandas.read_csv('../train_new_weather_turnstile.csv')\n",
    "test_dataframe = pandas.read_csv('../test_new_weather_turnstile.csv')\n",
    "\n",
    "predictions = prediction_dataframe(test_dataframe, dataframe,\\\n",
    "                                   categorical_features, \\\n",
    "                                   numeric_features_list_with_weight,\\\n",
    "                                   k, delta)\n",
    "sum_square_complex = compute_sum_square(test_dataframe['hourly_entries'], predictions)\n",
    "r_square_complex = compute_r_squared(test_dataframe['hourly_entries'], predictions)\n",
    "\n",
    "print \"SSE is \"+ str(sum_square_complex)\n",
    "print \"R2 is \"+ str(r_square_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this calculation, the SSE is 19062584953.9 and R2 is 0.712359529701. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexity: computational complexity is evaluated on predicting process. The time of predicting a record is O(n). n is total number of records. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three models were built using some features to predict hourly entries in NYC subway. They are simple linear model, two-level regression model and non-parametric model. Their evaluation of ten time running are as following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import summary\n",
    "\n",
    "#uncomment following line to get 10 splitting results\n",
    "#summary.run_for(10)\n",
    "\n",
    "summary.load_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result, two-level regression model performs better than other two models. And computational complexity of nonparametric model is greater than other two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Possible further improvements of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1, The features and parameters of all three model can be tuned to achieve better performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2, The two-level regression model only consider time as level one features. I think the performance will be better if the locations are considered in the model not only as a level indicator but also as a numerical variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3, The output of nonparametric model should be calculated in a more sophiscated way instead of simple average. Such ways include fitting a curve or training a small linear model based on k records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4, More non-linearity would bring better performance. Since the hourly_entries is a number related to some measure of physical world. There will be some restrictions on this value. And predicting the value may consider these resitrictions as well.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
